---

title: 스크래이퍼
tag: adjango

---

### 0. 개발 환경 조성

1. python3 설치
2. pip3 manager 설치 (pypi)
*	shell -> pip install 라이브러리명
*	제거 : uninstall 
*	검색 : search

3. Jupyter Notebook 설치
*	웹 기반의 인터랙티브 쉘 
*	anaconda python에는 기설치

-> 아나콘다 파이썬을 설치해서 개발환경 조성하자.
(가상환경 조성해야 하는지 여쭤보기
virtualenv)

### 1. BeautifulSoup

스크래이퍼가 뭔가 
-> 수집기. 긁어내는 도구

#### 임포트 문에서 발생할 수 있는 문제

*	페이지 찾을 수 없가나, URL 해석 에러  -> 404,500 에러 메세지 나옴
*	서버를 찾을 수 없는 경우

=> 각각 예외처리를 해준다. (try 문으로 캡슐화)

즉 getSiteHtml, getTitle 같은 범용 함수를 만들고 여기에 예외 처리를 만들어둬서 제작하는 방향으로.

### 2. 고급 HTML 분석

*	'페이지 인쇄' 링크, 더 나은 구조를 갖춘 모바일 버전의 사이트
*	자바스크립트 파일에 숨겨진 정보 찾기( 정리된 형태를 찾을 수 있을 수도)
*	원하는 정보가 페이지 URL에 있을 때도 있다.
*	이 웹사이트에 있는 데이터를 다른 웹사이트에서 수집한 것은 아닐까?

#### find()와 findAll()함수 사용법 익히기
`findAll(tag, attributes, recursive, text, limit, keywords)`
`find(tag, attributes, recursive, text, keywords)`

기억할 것 .findall()에 속성 목록을 넘기면 or 필터처럼 작용한다. 반대로 keyword 매개변수를 사용하면 and 필터처럼 동작한다.

##### 제목 뽑아내는 예제
```
from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen("http://www.pythonscraping.com/pages/page1.html")
bsObj = BeautifulSoup(html.read(), "html.parser")
print(bsObj.h1)
```

##### 제목 리스트 순서대로 가져오기 
```
from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen("http://www.pythonscraping.com/pages/warandpeace.html")
bsObj = BeautifulSoup(html.read(), "html.parser")
nameList = bsObj.findAll("span",{"class":"green"})
for name in nameList:
    print(name.get_text())
```

##### 갯수 가져오기
```
from urllib.request import urlopen
from bs4 import BeautifulSoup
html = urlopen("http://www.pythonscraping.com/pages/warandpeace.html")
bsObj = BeautifulSoup(html.read(), "html.parser")
nameList = bsObj.findAll(text="the prince")
print(len(nameList))
```
---
 
참고자료 

파이썬으로 웹 크롤러 만들기 (라이언 미첼 지음, 한선용 옮김, 한빛 미디어)

이진석 선생님 강좌 사이트 [nomade](https://www.askcompany.kr/vod/setup/43/)